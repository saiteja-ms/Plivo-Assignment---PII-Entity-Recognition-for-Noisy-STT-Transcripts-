# PII Named Entity Recognition (NER) System

This project implements a lightweight, high-performance Named Entity Recognition (NER) model for detecting **Personally Identifiable Information (PII)**.  
The goal is to achieve strong span-level accuracy **while maintaining a latency requirement of p95 â‰¤ 20 ms on CPU**.

## Project Overview

The system identifies the following PII entity types:

- **EMAIL**
- **PHONE**
- **PERSON_NAME**
- **DATE**
- **CITY**
- **LOCATION**
- **CREDIT_CARD**

All labels follow the **BIO tagging scheme**, and span-level predictions are returned in JSON format.

## Repository Structure

```
pii_ner_assignment/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”œâ”€â”€ dev.jsonl
â”‚   â””â”€â”€ test.jsonl
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ labels.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ eval_span_f1.py
â”‚   â”œâ”€â”€ measure_latency.py
â”‚   â””â”€â”€ run_full_experiment.py
â”‚
â”œâ”€â”€ out_minilm/
â”œâ”€â”€ tune_logs/
â”‚
â”œâ”€â”€ test_pred.json
â””â”€â”€ metrics_report.json
```

## ğŸ”§ Models Evaluated

| Model Name | Checkpoint | Purpose |
|-----------|------------|---------|
| **DistilBERT** | distilbert-base-uncased | Baseline |
| **MiniLM-L6-H384** | nreimers/MiniLM-L6-H384-uncased | â­ Best model |
| **MobileBERT** | google/mobilebert-uncased | Mobile-optimized |
| **BERT-Tiny** | prajjwal1/bert-tiny | Ultra-fast |
| **MiniLM-L6-v2** | microsoft/MiniLM-L6-v2 | Compact general model |

## ğŸ† Best Model Summary

**Best Model:** `nreimers/MiniLM-L6-H384-uncased`

Training Hyperparameters:
- learning rate: 3e-5
- batch size: 16
- epochs: 5
- max_length: 256
- device: CPU

## ğŸ“Š Final Dev Set Metrics

Macro-F1: **0.473**  
PII-only F1: **0.464**  
Non-PII F1: **0.497**

Per-Entity F1:
- CITY: 0.392
- CREDIT_CARD: 0.262
- DATE: 0.500
- EMAIL: 0.440
- LOCATION: 0.667
- PERSON_NAME: 0.632
- PHONE: 0.421

## âš¡ Latency (CPU)

p50: **11.79 ms**  
p95: **14.64 ms**

âœ” Meets requirement: p95 â‰¤ 20 ms

## ğŸ“¥ Submission Files

- **test_pred.json**
- **metrics_report.json**

## ğŸ› ï¸ Train

```
python src/train.py --model_name nreimers/MiniLM-L6-H384-uncased --train data/train.jsonl --dev data/dev.jsonl --out_dir out_minilm --batch_size 16 --epochs 5 --lr 3e-5 --device cpu
```

## ğŸ§ª Predict

```
python src/predict.py --model_dir out_minilm --input data/test.jsonl --output test_pred.json --device cpu
```

## ğŸ“ˆ Evaluate

```
python src/eval_span_f1.py --gold data/dev.jsonl --pred out_minilm/dev_pred.json
```

## âš¡ Latency

```
python src/measure_latency.py --model_dir out_minilm --input data/dev.jsonl --runs 50 --device cpu
```

## ğŸ§ª Optional Tuning

```
python src/run_full_experiment.py
```

## ğŸ“Œ Conclusion

The **MiniLM-L6-H384** model achieves:
- Macro-F1 = 0.473
- Very low latency (14.64 ms p95)
- Strong PII extraction performance

Meeting all assignment requirements.
